# AIç ”å‘è¾…åŠ©å¹³å° - åŽç«¯APIè®¾è®¡æ–‡æ¡£

## ðŸ“‹ æŠ€æœ¯æž¶æž„

### æ ¸å¿ƒæŠ€æœ¯æ ˆ
- **Webæ¡†æž¶**: FastAPI 0.104+
- **æ•°æ®åº“ORM**: SQLModel (SQLAlchemy + Pydantic)
- **æ•°æ®åº“**: PostgreSQL 15+
- **ç¼“å­˜**: Redis 7+
- **ä»»åŠ¡é˜Ÿåˆ—**: Celery + Redis
- **å‘é‡æ•°æ®åº“**: ChromaDB
- **è®¤è¯**: JWT (JSON Web Tokens)
- **åŠ å¯†**: cryptography (Fernet)
- **å¼‚æ­¥**: asyncio + asyncpg

### ç³»ç»Ÿæž¶æž„å›¾
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FastAPI åº”ç”¨å±‚                            â”‚
â”‚  è®¤è¯ä¸­é—´ä»¶ + CORS + å¼‚å¸¸å¤„ç† + è¯·æ±‚éªŒè¯                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    ä¸šåŠ¡é€»è¾‘å±‚                                â”‚
â”‚  ç”¨æˆ·æœåŠ¡ + AIæœåŠ¡ + GitæœåŠ¡ + éœ€æ±‚æœåŠ¡ + æµæ°´çº¿æœåŠ¡          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    æ•°æ®è®¿é—®å±‚                                â”‚
â”‚  SQLModel ORM + Redisç¼“å­˜ + ChromaDBå‘é‡åº“                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    å¤–éƒ¨æœåŠ¡å±‚                                â”‚
â”‚  OpenAI API + DeepSeek API + Git API + æ–‡ä»¶å­˜å‚¨              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    åŸºç¡€è®¾æ–½å±‚                                â”‚
â”‚  PostgreSQL + Redis + Celery + å¯¹è±¡å­˜å‚¨                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ—‚ï¸ é¡¹ç›®ç»“æž„

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPIåº”ç”¨å…¥å£
â”‚   â”œâ”€â”€ config.py               # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ database.py             # æ•°æ®åº“è¿žæŽ¥
â”‚   â”œâ”€â”€ dependencies.py         # ä¾èµ–æ³¨å…¥
â”‚   â”œâ”€â”€ middleware.py           # ä¸­é—´ä»¶
â”‚   â”œâ”€â”€ exceptions.py           # å¼‚å¸¸å¤„ç†
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                 # SQLModelæ•°æ®æ¨¡åž‹
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py            # åŸºç¡€æ¨¡åž‹
â”‚   â”‚   â”œâ”€â”€ user.py            # ç”¨æˆ·æ¨¡åž‹
â”‚   â”‚   â”œâ”€â”€ ai_model.py        # AIæ¨¡åž‹é…ç½®
â”‚   â”‚   â”œâ”€â”€ prompt.py          # Promptæ¨¡æ¿
â”‚   â”‚   â”œâ”€â”€ requirement.py     # éœ€æ±‚æ–‡æ¡£
â”‚   â”‚   â”œâ”€â”€ code_diff.py       # ä»£ç å·®å¼‚
â”‚   â”‚   â”œâ”€â”€ pipeline.py        # æµæ°´çº¿ä»»åŠ¡
â”‚   â”‚   â””â”€â”€ knowledge.py       # çŸ¥è¯†åº“
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas/                # Pydanticæ•°æ®æ¨¡å¼
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py            # åŸºç¡€æ¨¡å¼
â”‚   â”‚   â”œâ”€â”€ user.py            # ç”¨æˆ·ç›¸å…³æ¨¡å¼
â”‚   â”‚   â”œâ”€â”€ ai.py              # AIç›¸å…³æ¨¡å¼
â”‚   â”‚   â”œâ”€â”€ auth.py            # è®¤è¯æ¨¡å¼
â”‚   â”‚   â””â”€â”€ response.py        # å“åº”æ¨¡å¼
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                    # APIè·¯ç”±
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ v1/                # API v1ç‰ˆæœ¬
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py        # è®¤è¯æŽ¥å£
â”‚   â”‚   â”‚   â”œâ”€â”€ users.py       # ç”¨æˆ·ç®¡ç†
â”‚   â”‚   â”‚   â”œâ”€â”€ ai_models.py   # AIæ¨¡åž‹é…ç½®
â”‚   â”‚   â”‚   â”œâ”€â”€ prompts.py     # Promptæ¨¡æ¿
â”‚   â”‚   â”‚   â”œâ”€â”€ requirements.py # éœ€æ±‚ç®¡ç†
â”‚   â”‚   â”‚   â”œâ”€â”€ code_diff.py   # ä»£ç å·®å¼‚
â”‚   â”‚   â”‚   â”œâ”€â”€ pipelines.py   # æµæ°´çº¿
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py        # AIå¯¹è¯
â”‚   â”‚   â”‚   â””â”€â”€ knowledge.py   # çŸ¥è¯†åº“
â”‚   â”‚   â””â”€â”€ deps.py            # APIä¾èµ–
â”‚   â”‚
â”‚   â”œâ”€â”€ services/               # ä¸šåŠ¡æœåŠ¡å±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ auth_service.py    # è®¤è¯æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ user_service.py    # ç”¨æˆ·æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ ai_service.py      # AIæœåŠ¡
â”‚   â”‚   â”œâ”€â”€ git_service.py     # GitæœåŠ¡
â”‚   â”‚   â”œâ”€â”€ requirement_service.py # éœ€æ±‚æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ pipeline_service.py # æµæ°´çº¿æœåŠ¡
â”‚   â”‚   â””â”€â”€ knowledge_service.py # çŸ¥è¯†åº“æœåŠ¡
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                   # æ ¸å¿ƒåŠŸèƒ½
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ security.py        # å®‰å…¨ç›¸å…³
â”‚   â”‚   â”œâ”€â”€ encryption.py      # åŠ å¯†è§£å¯†
â”‚   â”‚   â”œâ”€â”€ jwt.py             # JWTå¤„ç†
â”‚   â”‚   â””â”€â”€ permissions.py     # æƒé™æŽ§åˆ¶
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                  # å·¥å…·å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ logger.py          # æ—¥å¿—é…ç½®
â”‚   â”‚   â”œâ”€â”€ validators.py      # æ•°æ®éªŒè¯
â”‚   â”‚   â”œâ”€â”€ formatters.py      # æ•°æ®æ ¼å¼åŒ–
â”‚   â”‚   â””â”€â”€ helpers.py         # è¾…åŠ©å‡½æ•°
â”‚   â”‚
â”‚   â”œâ”€â”€ tasks/                  # Celeryä»»åŠ¡
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ celery_app.py      # Celeryåº”ç”¨
â”‚   â”‚   â”œâ”€â”€ ai_tasks.py        # AIç›¸å…³ä»»åŠ¡
â”‚   â”‚   â”œâ”€â”€ git_tasks.py       # Gitç›¸å…³ä»»åŠ¡
â”‚   â”‚   â””â”€â”€ pipeline_tasks.py  # æµæ°´çº¿ä»»åŠ¡
â”‚   â”‚
â”‚   â””â”€â”€ tests/                  # æµ‹è¯•
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ conftest.py        # æµ‹è¯•é…ç½®
â”‚       â”œâ”€â”€ test_auth.py       # è®¤è¯æµ‹è¯•
â”‚       â”œâ”€â”€ test_users.py      # ç”¨æˆ·æµ‹è¯•
â”‚       â””â”€â”€ test_ai.py         # AIåŠŸèƒ½æµ‹è¯•
â”‚
â”œâ”€â”€ migrations/                 # æ•°æ®åº“è¿ç§»
â”œâ”€â”€ scripts/                    # è„šæœ¬æ–‡ä»¶
â”œâ”€â”€ docker/                     # Dockeré…ç½®
â”œâ”€â”€ requirements.txt            # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ requirements-dev.txt        # å¼€å‘ä¾èµ–
â”œâ”€â”€ .env.example               # çŽ¯å¢ƒå˜é‡ç¤ºä¾‹
â”œâ”€â”€ docker-compose.yml         # Docker Compose
â”œâ”€â”€ Dockerfile                 # Dockeré•œåƒ
â””â”€â”€ README.md                  # é¡¹ç›®è¯´æ˜Ž
```

## ðŸ”§ æ ¸å¿ƒé…ç½®

### çŽ¯å¢ƒå˜é‡é…ç½® (.env)
```bash
# åº”ç”¨é…ç½®
APP_NAME=AIç ”å‘è¾…åŠ©å¹³å°
APP_VERSION=1.0.0
DEBUG=True
SECRET_KEY=your-secret-key-here

# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/ai_platform
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=30

# Redisé…ç½®
REDIS_URL=redis://localhost:6379/0
REDIS_CACHE_TTL=3600

# JWTé…ç½®
JWT_SECRET_KEY=your-jwt-secret-key
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7

# åŠ å¯†é…ç½®
ENCRYPTION_KEY=your-fernet-encryption-key

# AIæœåŠ¡é…ç½®
OPENAI_API_KEY=your-openai-api-key
DEEPSEEK_API_KEY=your-deepseek-api-key
SPARK_API_KEY=your-spark-api-key
DOUBAO_API_KEY=your-doubao-api-key

# æ–‡ä»¶å­˜å‚¨é…ç½®
UPLOAD_DIR=./uploads
MAX_FILE_SIZE=10485760  # 10MB
ALLOWED_EXTENSIONS=.txt,.md,.pdf,.doc,.docx

# Celeryé…ç½®
CELERY_BROKER_URL=redis://localhost:6379/1
CELERY_RESULT_BACKEND=redis://localhost:6379/2

# ChromaDBé…ç½®
CHROMA_DB_PATH=./chroma_db
CHROMA_COLLECTION_NAME=ai_platform_knowledge

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
LOG_FILE=./logs/app.log
```

## ðŸ“Š æ•°æ®æ¨¡åž‹è®¾è®¡

### åŸºç¡€æ¨¡åž‹ (app/models/base.py)
```python
from sqlmodel import SQLModel, Field
from datetime import datetime
from typing import Optional
import uuid

class BaseModel(SQLModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()), primary_key=True)
    created_at: datetime = Field(default_factory=datetime.utcnow)
    updated_at: Optional[datetime] = Field(default=None)
    is_deleted: bool = Field(default=False)
    
    class Config:
        from_attributes = True
```

### ç”¨æˆ·æ¨¡åž‹ (app/models/user.py)
```python
from sqlmodel import SQLModel, Field, Relationship
from typing import Optional, List
from enum import Enum
from .base import BaseModel

class UserRole(str, Enum):
    ADMIN = "admin"
    DEVELOPER = "developer"
    TESTER = "tester"
    USER = "user"

class User(BaseModel, table=True):
    __tablename__ = "users"
    
    username: str = Field(unique=True, index=True)
    email: str = Field(unique=True, index=True)
    hashed_password: str
    nickname: Optional[str] = None
    avatar: Optional[str] = None
    department: Optional[str] = None
    position: Optional[str] = None
    role: UserRole = Field(default=UserRole.USER)
    is_active: bool = Field(default=True)
    last_login: Optional[datetime] = None
    
    # å…³è”å…³ç³»
    ai_model_configs: List["AIModelConfig"] = Relationship(back_populates="user")
    prompt_templates: List["PromptTemplate"] = Relationship(back_populates="user")
    requirements: List["RequirementDocument"] = Relationship(back_populates="user")
```

### AIæ¨¡åž‹é…ç½® (app/models/ai_model.py)
```python
from sqlmodel import SQLModel, Field, Relationship
from typing import Optional
from enum import Enum
from .base import BaseModel

class AIProvider(str, Enum):
    OPENAI = "openai"
    DEEPSEEK = "deepseek"
    SPARK = "spark"
    DOUBAO = "doubao"
    GEMINI = "gemini"
    CLAUDE = "claude"

class AIModelConfig(BaseModel, table=True):
    __tablename__ = "ai_model_configs"
    
    name: str
    provider: AIProvider
    base_url: str
    api_key_encrypted: str  # åŠ å¯†å­˜å‚¨
    model: str
    max_tokens: Optional[int] = Field(default=4096)
    temperature: Optional[float] = Field(default=0.7)
    is_default: bool = Field(default=False)
    is_active: bool = Field(default=True)
    
    # å¤–é”®
    user_id: str = Field(foreign_key="users.id")
    user: User = Relationship(back_populates="ai_model_configs")
```

### Promptæ¨¡æ¿ (app/models/prompt.py)
```python
from sqlmodel import SQLModel, Field, Relationship, JSON
from typing import Optional, List
from enum import Enum
from .base import BaseModel

class PromptCategory(str, Enum):
    REQUIREMENT = "requirement"
    CODE_REVIEW = "code_review"
    TEST_CASE = "test_case"
    GENERAL = "general"

class PromptTemplate(BaseModel, table=True):
    __tablename__ = "prompt_templates"
    
    name: str
    identifier: str = Field(unique=True, index=True)
    content: str
    description: Optional[str] = None
    category: PromptCategory
    tags: List[str] = Field(default=[], sa_column=JSON)
    variables: List[str] = Field(default=[], sa_column=JSON)
    is_public: bool = Field(default=False)
    usage_count: int = Field(default=0)
    
    # å¤–é”®
    user_id: str = Field(foreign_key="users.id")
    user: User = Relationship(back_populates="prompt_templates")
```

## ðŸ” è®¤è¯ä¸Žå®‰å…¨

### JWTè®¤è¯ (app/core/jwt.py)
```python
from datetime import datetime, timedelta
from typing import Optional
import jwt
from app.config import settings

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=settings.JWT_ACCESS_TOKEN_EXPIRE_MINUTES)
    
    to_encode.update({"exp": expire, "type": "access"})
    encoded_jwt = jwt.encode(to_encode, settings.JWT_SECRET_KEY, algorithm=settings.JWT_ALGORITHM)
    return encoded_jwt

def create_refresh_token(data: dict):
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(days=settings.JWT_REFRESH_TOKEN_EXPIRE_DAYS)
    to_encode.update({"exp": expire, "type": "refresh"})
    encoded_jwt = jwt.encode(to_encode, settings.JWT_SECRET_KEY, algorithm=settings.JWT_ALGORITHM)
    return encoded_jwt

def verify_token(token: str) -> Optional[dict]:
    try:
        payload = jwt.decode(token, settings.JWT_SECRET_KEY, algorithms=[settings.JWT_ALGORITHM])
        return payload
    except jwt.PyJWTError:
        return None
```

### åŠ å¯†æœåŠ¡ (app/core/encryption.py)
```python
from cryptography.fernet import Fernet
from app.config import settings

class EncryptionService:
    def __init__(self):
        self.fernet = Fernet(settings.ENCRYPTION_KEY.encode())
    
    def encrypt(self, data: str) -> str:
        """åŠ å¯†å­—ç¬¦ä¸²"""
        return self.fernet.encrypt(data.encode()).decode()
    
    def decrypt(self, encrypted_data: str) -> str:
        """è§£å¯†å­—ç¬¦ä¸²"""
        return self.fernet.decrypt(encrypted_data.encode()).decode()

encryption_service = EncryptionService()
```

## ðŸš€ APIæŽ¥å£è®¾è®¡

### è®¤è¯æŽ¥å£ (app/api/v1/auth.py)
```python
from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.security import OAuth2PasswordRequestForm
from sqlmodel import Session
from app.schemas.auth import Token, UserLogin, UserRegister
from app.services.auth_service import AuthService
from app.dependencies import get_db

router = APIRouter(prefix="/auth", tags=["è®¤è¯"])

@router.post("/login", response_model=Token)
async def login(
    form_data: OAuth2PasswordRequestForm = Depends(),
    db: Session = Depends(get_db)
):
    """ç”¨æˆ·ç™»å½•"""
    auth_service = AuthService(db)
    token = await auth_service.authenticate_user(form_data.username, form_data.password)
    if not token:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯"
        )
    return token

@router.post("/refresh", response_model=Token)
async def refresh_token(
    refresh_token: str,
    db: Session = Depends(get_db)
):
    """åˆ·æ–°è®¿é—®ä»¤ç‰Œ"""
    auth_service = AuthService(db)
    token = await auth_service.refresh_access_token(refresh_token)
    if not token:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="åˆ·æ–°ä»¤ç‰Œæ— æ•ˆ"
        )
    return token

@router.post("/logout")
async def logout():
    """ç”¨æˆ·ç™»å‡º"""
    return {"message": "ç™»å‡ºæˆåŠŸ"}
```

### AIæ¨¡åž‹é…ç½®æŽ¥å£ (app/api/v1/ai_models.py)
```python
from fastapi import APIRouter, Depends, HTTPException, status
from sqlmodel import Session
from typing import List
from app.schemas.ai import AIModelConfigCreate, AIModelConfigUpdate, AIModelConfigResponse
from app.services.ai_service import AIModelService
from app.dependencies import get_db, get_current_user
from app.models.user import User

router = APIRouter(prefix="/ai/models", tags=["AIæ¨¡åž‹é…ç½®"])

@router.get("/", response_model=List[AIModelConfigResponse])
async def get_ai_models(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """èŽ·å–AIæ¨¡åž‹é…ç½®åˆ—è¡¨"""
    service = AIModelService(db)
    return await service.get_user_models(current_user.id)

@router.post("/", response_model=AIModelConfigResponse)
async def create_ai_model(
    model_data: AIModelConfigCreate,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """åˆ›å»ºAIæ¨¡åž‹é…ç½®"""
    service = AIModelService(db)
    return await service.create_model(model_data, current_user.id)

@router.post("/{model_id}/test")
async def test_ai_model(
    model_id: str,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """æµ‹è¯•AIæ¨¡åž‹è¿žæŽ¥"""
    service = AIModelService(db)
    result = await service.test_model_connection(model_id, current_user.id)
    return result
```

## ðŸ”„ å¼‚æ­¥ä»»åŠ¡è®¾è®¡

### Celeryé…ç½® (app/tasks/celery_app.py)
```python
from celery import Celery
from app.config import settings

celery_app = Celery(
    "ai_platform",
    broker=settings.CELERY_BROKER_URL,
    backend=settings.CELERY_RESULT_BACKEND,
    include=[
        "app.tasks.ai_tasks",
        "app.tasks.git_tasks",
        "app.tasks.pipeline_tasks"
    ]
)

celery_app.conf.update(
    task_serializer="json",
    accept_content=["json"],
    result_serializer="json",
    timezone="UTC",
    enable_utc=True,
    task_track_started=True,
    task_time_limit=30 * 60,  # 30åˆ†é’Ÿè¶…æ—¶
    task_soft_time_limit=25 * 60,  # 25åˆ†é’Ÿè½¯è¶…æ—¶
)
```

### AIä»»åŠ¡ (app/tasks/ai_tasks.py)
```python
from celery import current_task
from app.tasks.celery_app import celery_app
from app.services.ai_service import AIService
from app.database import get_db

@celery_app.task(bind=True)
def parse_requirement_task(self, requirement_id: str, model_config_id: str, prompt_template_id: str = None):
    """å¼‚æ­¥è§£æžéœ€æ±‚ä»»åŠ¡"""
    try:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        current_task.update_state(
            state="PROGRESS",
            meta={"current": 10, "total": 100, "status": "å¼€å§‹è§£æžéœ€æ±‚..."}
        )
        
        db = next(get_db())
        ai_service = AIService(db)
        
        # æ‰§è¡ŒAIè§£æž
        result = ai_service.parse_requirement(requirement_id, model_config_id, prompt_template_id)
        
        current_task.update_state(
            state="SUCCESS",
            meta={"current": 100, "total": 100, "status": "éœ€æ±‚è§£æžå®Œæˆ", "result": result}
        )
        
        return result
        
    except Exception as exc:
        current_task.update_state(
            state="FAILURE",
            meta={"current": 0, "total": 100, "status": f"è§£æžå¤±è´¥: {str(exc)}"}
        )
        raise exc

@celery_app.task(bind=True)
def code_review_task(self, code_diff_id: str, requirement_id: str, model_config_id: str):
    """å¼‚æ­¥ä»£ç è¯„å®¡ä»»åŠ¡"""
    try:
        current_task.update_state(
            state="PROGRESS",
            meta={"current": 20, "total": 100, "status": "å¼€å§‹ä»£ç è¯„å®¡..."}
        )
        
        db = next(get_db())
        ai_service = AIService(db)
        
        # æ‰§è¡Œä»£ç è¯„å®¡
        result = ai_service.review_code(code_diff_id, requirement_id, model_config_id)
        
        current_task.update_state(
            state="SUCCESS",
            meta={"current": 100, "total": 100, "status": "ä»£ç è¯„å®¡å®Œæˆ", "result": result}
        )
        
        return result
        
    except Exception as exc:
        current_task.update_state(
            state="FAILURE",
            meta={"current": 0, "total": 100, "status": f"è¯„å®¡å¤±è´¥: {str(exc)}"}
        )
        raise exc
```

## ðŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### Redisç¼“å­˜ç­–ç•¥
```python
from redis import Redis
from app.config import settings
import json
import pickle

class CacheService:
    def __init__(self):
        self.redis = Redis.from_url(settings.REDIS_URL)
    
    async def get(self, key: str):
        """èŽ·å–ç¼“å­˜"""
        data = self.redis.get(key)
        if data:
            return pickle.loads(data)
        return None
    
    async def set(self, key: str, value, ttl: int = settings.REDIS_CACHE_TTL):
        """è®¾ç½®ç¼“å­˜"""
        self.redis.setex(key, ttl, pickle.dumps(value))
    
    async def delete(self, key: str):
        """åˆ é™¤ç¼“å­˜"""
        self.redis.delete(key)
    
    async def get_user_models(self, user_id: str):
        """èŽ·å–ç”¨æˆ·AIæ¨¡åž‹é…ç½®ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        cache_key = f"user_models:{user_id}"
        cached_data = await self.get(cache_key)
        if cached_data:
            return cached_data
        
        # ä»Žæ•°æ®åº“èŽ·å–æ•°æ®
        # ... æ•°æ®åº“æŸ¥è¯¢é€»è¾‘
        
        # ç¼“å­˜ç»“æžœ
        await self.set(cache_key, result)
        return result
```

### æ•°æ®åº“è¿žæŽ¥æ± 
```python
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker
from app.config import settings

engine = create_async_engine(
    settings.DATABASE_URL,
    pool_size=settings.DATABASE_POOL_SIZE,
    max_overflow=settings.DATABASE_MAX_OVERFLOW,
    pool_pre_ping=True,
    pool_recycle=3600,
    echo=settings.DEBUG
)

AsyncSessionLocal = sessionmaker(
    engine, class_=AsyncSession, expire_on_commit=False
)

async def get_db():
    async with AsyncSessionLocal() as session:
        try:
            yield session
        finally:
            await session.close()
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åŽæ›´æ–°**: 2024å¹´12æœˆ  
**è´Ÿè´£äºº**: åŽç«¯å›¢é˜Ÿ


# AIç ”å‘è¾…åŠ©å¹³å° - æ•°æ®åº“è®¾è®¡æ–‡æ¡£

## ðŸ“Š æ•°æ®åº“æ¦‚è¿°

### æŠ€æœ¯é€‰åž‹
- **æ•°æ®åº“**: PostgreSQL 15+
- **ORM**: SQLModel (SQLAlchemy + Pydantic)
- **è¿ç§»å·¥å…·**: Alembic
- **è¿žæŽ¥æ± **: asyncpg + SQLAlchemyå¼‚æ­¥å¼•æ“Ž

### è®¾è®¡åŽŸåˆ™
- **è§„èŒƒåŒ–**: éµå¾ªç¬¬ä¸‰èŒƒå¼ï¼Œå‡å°‘æ•°æ®å†—ä½™
- **æ€§èƒ½ä¼˜åŒ–**: åˆç†ä½¿ç”¨ç´¢å¼•ï¼Œä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
- **æ‰©å±•æ€§**: æ”¯æŒæ°´å¹³å’Œåž‚ç›´æ‰©å±•
- **å®‰å…¨æ€§**: æ•æ„Ÿæ•°æ®åŠ å¯†å­˜å‚¨
- **å®¡è®¡**: è®°å½•æ•°æ®å˜æ›´åŽ†å²

## ðŸ—ƒï¸ æ•°æ®è¡¨è®¾è®¡

### 1. ç”¨æˆ·ç®¡ç†

#### users (ç”¨æˆ·è¡¨)
```sql
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    hashed_password VARCHAR(255) NOT NULL,
    nickname VARCHAR(100),
    avatar TEXT,
    department VARCHAR(100),
    position VARCHAR(100),
    role VARCHAR(20) DEFAULT 'user' CHECK (role IN ('admin', 'developer', 'tester', 'user')),
    is_active BOOLEAN DEFAULT true,
    last_login TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE,
    is_deleted BOOLEAN DEFAULT false
);

-- ç´¢å¼•
CREATE INDEX idx_users_username ON users(username);
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_role ON users(role);
CREATE INDEX idx_users_is_active ON users(is_active);
```

#### user_sessions (ç”¨æˆ·ä¼šè¯è¡¨)
```sql
CREATE TABLE user_sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    refresh_token_hash VARCHAR(255) NOT NULL,
    device_info JSONB,
    ip_address INET,
    expires_at TIMESTAMP WITH TIME ZONE NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    is_revoked BOOLEAN DEFAULT false
);

-- ç´¢å¼•
CREATE INDEX idx_user_sessions_user_id ON user_sessions(user_id);
CREATE INDEX idx_user_sessions_expires_at ON user_sessions(expires_at);
CREATE INDEX idx_user_sessions_refresh_token_hash ON user_sessions(refresh_token_hash);
```

### 2. AIæ¨¡åž‹é…ç½®

#### ai_model_configs (AIæ¨¡åž‹é…ç½®è¡¨)
```sql
CREATE TABLE ai_model_configs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(100) NOT NULL,
    provider VARCHAR(20) NOT NULL CHECK (provider IN ('openai', 'deepseek', 'spark', 'doubao', 'gemini', 'claude')),
    base_url TEXT NOT NULL,
    api_key_encrypted TEXT NOT NULL,
    model VARCHAR(100) NOT NULL,
    max_tokens INTEGER DEFAULT 4096,
    temperature DECIMAL(3,2) DEFAULT 0.7 CHECK (temperature >= 0 AND temperature <= 2),
    is_default BOOLEAN DEFAULT false,
    is_active BOOLEAN DEFAULT true,
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE,
    is_deleted BOOLEAN DEFAULT false
);

-- ç´¢å¼•
CREATE INDEX idx_ai_model_configs_user_id ON ai_model_configs(user_id);
CREATE INDEX idx_ai_model_configs_provider ON ai_model_configs(provider);
CREATE INDEX idx_ai_model_configs_is_active ON ai_model_configs(is_active);
CREATE UNIQUE INDEX idx_ai_model_configs_user_default ON ai_model_configs(user_id) WHERE is_default = true;
```

### 3. Promptæ¨¡æ¿

#### prompt_templates (Promptæ¨¡æ¿è¡¨)
```sql
CREATE TABLE prompt_templates (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(200) NOT NULL,
    identifier VARCHAR(100) UNIQUE NOT NULL,
    content TEXT NOT NULL,
    description TEXT,
    category VARCHAR(20) NOT NULL CHECK (category IN ('requirement', 'code_review', 'test_case', 'general')),
    tags JSONB DEFAULT '[]',
    variables JSONB DEFAULT '[]',
    is_public BOOLEAN DEFAULT false,
    usage_count INTEGER DEFAULT 0,
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE,
    is_deleted BOOLEAN DEFAULT false
);

-- ç´¢å¼•
CREATE INDEX idx_prompt_templates_user_id ON prompt_templates(user_id);
CREATE INDEX idx_prompt_templates_category ON prompt_templates(category);
CREATE INDEX idx_prompt_templates_is_public ON prompt_templates(is_public);
CREATE INDEX idx_prompt_templates_identifier ON prompt_templates(identifier);
CREATE INDEX idx_prompt_templates_tags ON prompt_templates USING GIN(tags);
```

### 4. éœ€æ±‚ç®¡ç†

#### requirement_documents (éœ€æ±‚æ–‡æ¡£è¡¨)
```sql
CREATE TABLE requirement_documents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(200) NOT NULL,
    original_content TEXT NOT NULL,
    optimized_content TEXT,
    source VARCHAR(20) DEFAULT 'manual' CHECK (source IN ('upload', 'manual')),
    original_filename VARCHAR(255),
    file_path TEXT,
    file_size INTEGER,
    mime_type VARCHAR(100),
    status VARCHAR(20) DEFAULT 'pending' CHECK (status IN ('pending', 'processing', 'completed', 'failed')),
    parse_task_id UUID,
    error_message TEXT,
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE,
    is_deleted BOOLEAN DEFAULT false
);

-- ç´¢å¼•
CREATE INDEX idx_requirement_documents_user_id ON requirement_documents(user_id);
CREATE INDEX idx_requirement_documents_status ON requirement_documents(status);
CREATE INDEX idx_requirement_documents_source ON requirement_documents(source);
CREATE INDEX idx_requirement_documents_created_at ON requirement_documents(created_at);
```

### 5. Gité…ç½®

#### git_credentials (Gitå‡­è¯è¡¨)
```sql
CREATE TABLE git_credentials (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(100) NOT NULL,
    git_username VARCHAR(100) NOT NULL,
    git_email VARCHAR(100) NOT NULL,
    access_token_encrypted TEXT NOT NULL,
    provider VARCHAR(20) DEFAULT 'github' CHECK (provider IN ('github', 'gitlab', 'gitee', 'bitbucket')),
    is_default BOOLEAN DEFAULT false,
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE,
    is_deleted BOOLEAN DEFAULT false
);

-- ç´¢å¼•
CREATE INDEX idx_git_credentials_user_id ON git_credentials(user_id);
CREATE INDEX idx_git_credentials_provider ON git_credentials(provider);
CREATE UNIQUE INDEX idx_git_credentials_user_default ON git_credentials(user_id) WHERE is_default = true;
```

#### git_repositories (Gitä»“åº“è¡¨)
```sql
CREATE TABLE git_repositories (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    alias VARCHAR(100) NOT NULL,
    repository_url TEXT NOT NULL,
    branch VARCHAR(100) DEFAULT 'main',
    credential_id UUID REFERENCES git_credentials(id) ON DELETE SET NULL,
    is_active BOOLEAN DEFAULT true,
    last_sync_at TIMESTAMP WITH TIME ZONE,
    sync_status VARCHAR(20) DEFAULT 'pending' CHECK (sync_status IN ('pending', 'syncing', 'success', 'failed')),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE,
    is_deleted BOOLEAN DEFAULT false
);

-- ç´¢å¼•
CREATE INDEX idx_git_repositories_user_id ON git_repositories(user_id);
CREATE INDEX idx_git_repositories_credential_id ON git_repositories(credential_id);
CREATE INDEX idx_git_repositories_is_active ON git_repositories(is_active);
```

### 6. ä»£ç å·®å¼‚

#### code_diff_tasks (ä»£ç å·®å¼‚ä»»åŠ¡è¡¨)
```sql
CREATE TABLE code_diff_tasks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(200) NOT NULL,
    repository_id UUID NOT NULL REFERENCES git_repositories(id) ON DELETE CASCADE,
    compare_type VARCHAR(20) NOT NULL CHECK (compare_type IN ('branch', 'commit')),
    source_ref VARCHAR(100) NOT NULL,
    target_ref VARCHAR(100) NOT NULL,
    diff_content TEXT,
    diff_stats JSONB,
    status VARCHAR(20) DEFAULT 'pending' CHECK (status IN ('pending', 'running', 'completed', 'failed')),
    error_message TEXT,
    started_at TIMESTAMP WITH TIME ZONE,
    completed_at TIMESTAMP WITH TIME ZONE,
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE,
    is_deleted BOOLEAN DEFAULT false
);

-- ç´¢å¼•
CREATE INDEX idx_code_diff_tasks_user_id ON code_diff_tasks(user_id);
CREATE INDEX idx_code_diff_tasks_repository_id ON code_diff_tasks(repository_id);
CREATE INDEX idx_code_diff_tasks_status ON code_diff_tasks(status);
CREATE INDEX idx_code_diff_tasks_created_at ON code_diff_tasks(created_at);
```

### 7. æµæ°´çº¿ä»»åŠ¡

#### pipeline_tasks (æµæ°´çº¿ä»»åŠ¡è¡¨)
```sql
CREATE TABLE pipeline_tasks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(200) NOT NULL,
    type VARCHAR(20) NOT NULL CHECK (type IN ('code_review', 'test_generation', 'requirement_analysis')),
    code_diff_task_id UUID REFERENCES code_diff_tasks(id) ON DELETE SET NULL,
    requirement_document_id UUID REFERENCES requirement_documents(id) ON DELETE SET NULL,
    prompt_template_id UUID REFERENCES prompt_templates(id) ON DELETE SET NULL,
    ai_model_config_id UUID REFERENCES ai_model_configs(id) ON DELETE SET NULL,
    knowledge_base_id UUID,
    config JSONB DEFAULT '{}',
    result JSONB,
    status VARCHAR(20) DEFAULT 'pending' CHECK (status IN ('pending', 'running', 'completed', 'failed')),
    progress INTEGER DEFAULT 0 CHECK (progress >= 0 AND progress <= 100),
    error_message TEXT,
    started_at TIMESTAMP WITH TIME ZONE,
    completed_at TIMESTAMP WITH TIME ZONE,
    celery_task_id UUID,
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE,
    is_deleted BOOLEAN DEFAULT false
);

-- ç´¢å¼•
CREATE INDEX idx_pipeline_tasks_user_id ON pipeline_tasks(user_id);
CREATE INDEX idx_pipeline_tasks_type ON pipeline_tasks(type);
CREATE INDEX idx_pipeline_tasks_status ON pipeline_tasks(status);
CREATE INDEX idx_pipeline_tasks_code_diff_task_id ON pipeline_tasks(code_diff_task_id);
CREATE INDEX idx_pipeline_tasks_requirement_document_id ON pipeline_tasks(requirement_document_id);
CREATE INDEX idx_pipeline_tasks_created_at ON pipeline_tasks(created_at);
```

### 8. AIå¯¹è¯

#### ai_conversations (AIå¯¹è¯è¡¨)
```sql
CREATE TABLE ai_conversations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    title VARCHAR(200) NOT NULL,
    ai_model_config_id UUID NOT NULL REFERENCES ai_model_configs(id) ON DELETE CASCADE,
    total_tokens INTEGER DEFAULT 0,
    message_count INTEGER DEFAULT 0,
    last_message_at TIMESTAMP WITH TIME ZONE,
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE,
    is_deleted BOOLEAN DEFAULT false
);

-- ç´¢å¼•
CREATE INDEX idx_ai_conversations_user_id ON ai_conversations(user_id);
CREATE INDEX idx_ai_conversations_ai_model_config_id ON ai_conversations(ai_model_config_id);
CREATE INDEX idx_ai_conversations_last_message_at ON ai_conversations(last_message_at);
```

#### ai_messages (AIæ¶ˆæ¯è¡¨)
```sql
CREATE TABLE ai_messages (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    conversation_id UUID NOT NULL REFERENCES ai_conversations(id) ON DELETE CASCADE,
    role VARCHAR(20) NOT NULL CHECK (role IN ('user', 'assistant', 'system')),
    content TEXT NOT NULL,
    tokens INTEGER,
    prompt_template_id UUID REFERENCES prompt_templates(id) ON DELETE SET NULL,
    context JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- ç´¢å¼•
CREATE INDEX idx_ai_messages_conversation_id ON ai_messages(conversation_id);
CREATE INDEX idx_ai_messages_role ON ai_messages(role);
CREATE INDEX idx_ai_messages_created_at ON ai_messages(created_at);
```

### 9. çŸ¥è¯†åº“

#### knowledge_bases (çŸ¥è¯†åº“è¡¨)
```sql
CREATE TABLE knowledge_bases (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(200) NOT NULL,
    description TEXT,
    collection_name VARCHAR(100) UNIQUE NOT NULL,
    document_count INTEGER DEFAULT 0,
    total_size BIGINT DEFAULT 0,
    is_public BOOLEAN DEFAULT false,
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE,
    is_deleted BOOLEAN DEFAULT false
);

-- ç´¢å¼•
CREATE INDEX idx_knowledge_bases_user_id ON knowledge_bases(user_id);
CREATE INDEX idx_knowledge_bases_is_public ON knowledge_bases(is_public);
CREATE INDEX idx_knowledge_bases_collection_name ON knowledge_bases(collection_name);
```

#### knowledge_documents (çŸ¥è¯†æ–‡æ¡£è¡¨)
```sql
CREATE TABLE knowledge_documents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    knowledge_base_id UUID NOT NULL REFERENCES knowledge_bases(id) ON DELETE CASCADE,
    filename VARCHAR(255) NOT NULL,
    file_path TEXT NOT NULL,
    file_size INTEGER NOT NULL,
    mime_type VARCHAR(100),
    content_hash VARCHAR(64),
    chunk_count INTEGER DEFAULT 0,
    processing_status VARCHAR(20) DEFAULT 'pending' CHECK (processing_status IN ('pending', 'processing', 'completed', 'failed')),
    error_message TEXT,
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE,
    is_deleted BOOLEAN DEFAULT false
);

-- ç´¢å¼•
CREATE INDEX idx_knowledge_documents_knowledge_base_id ON knowledge_documents(knowledge_base_id);
CREATE INDEX idx_knowledge_documents_user_id ON knowledge_documents(user_id);
CREATE INDEX idx_knowledge_documents_processing_status ON knowledge_documents(processing_status);
CREATE INDEX idx_knowledge_documents_content_hash ON knowledge_documents(content_hash);
```

### 10. ç³»ç»Ÿæ—¥å¿—

#### system_logs (ç³»ç»Ÿæ—¥å¿—è¡¨)
```sql
CREATE TABLE system_logs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    level VARCHAR(10) NOT NULL CHECK (level IN ('DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL')),
    message TEXT NOT NULL,
    module VARCHAR(100),
    function_name VARCHAR(100),
    user_id UUID REFERENCES users(id) ON DELETE SET NULL,
    request_id UUID,
    ip_address INET,
    user_agent TEXT,
    extra_data JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- ç´¢å¼•
CREATE INDEX idx_system_logs_level ON system_logs(level);
CREATE INDEX idx_system_logs_user_id ON system_logs(user_id);
CREATE INDEX idx_system_logs_created_at ON system_logs(created_at);
CREATE INDEX idx_system_logs_module ON system_logs(module);

-- åˆ†åŒºè¡¨ï¼ˆæŒ‰æœˆåˆ†åŒºï¼‰
CREATE TABLE system_logs_y2024m01 PARTITION OF system_logs
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
```

## ðŸ”§ æ•°æ®åº“ä¼˜åŒ–

### 1. ç´¢å¼•ç­–ç•¥
```sql
-- å¤åˆç´¢å¼•
CREATE INDEX idx_pipeline_tasks_user_status ON pipeline_tasks(user_id, status);
CREATE INDEX idx_ai_messages_conversation_created ON ai_messages(conversation_id, created_at);

-- éƒ¨åˆ†ç´¢å¼•
CREATE INDEX idx_users_active_username ON users(username) WHERE is_active = true;
CREATE INDEX idx_ai_model_configs_active ON ai_model_configs(user_id) WHERE is_active = true;

-- è¡¨è¾¾å¼ç´¢å¼•
CREATE INDEX idx_users_lower_email ON users(LOWER(email));
CREATE INDEX idx_prompt_templates_search ON prompt_templates USING gin(to_tsvector('english', name || ' ' || description));
```

### 2. åˆ†åŒºç­–ç•¥
```sql
-- æŒ‰æ—¶é—´åˆ†åŒºæ—¥å¿—è¡¨
CREATE TABLE system_logs (
    id UUID DEFAULT gen_random_uuid(),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    -- å…¶ä»–å­—æ®µ...
) PARTITION BY RANGE (created_at);

-- åˆ›å»ºåˆ†åŒº
CREATE TABLE system_logs_y2024m01 PARTITION OF system_logs
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

CREATE TABLE system_logs_y2024m02 PARTITION OF system_logs
FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');
```

### 3. æ€§èƒ½ä¼˜åŒ–
```sql
-- å¯ç”¨ç»Ÿè®¡ä¿¡æ¯è‡ªåŠ¨æ”¶é›†
ALTER TABLE users SET (autovacuum_analyze_scale_factor = 0.05);
ALTER TABLE ai_messages SET (autovacuum_analyze_scale_factor = 0.02);

-- è®¾ç½®è¡¨çš„å¡«å……å› å­
ALTER TABLE users SET (fillfactor = 90);
ALTER TABLE ai_conversations SET (fillfactor = 85);

-- åˆ›å»ºç‰©åŒ–è§†å›¾
CREATE MATERIALIZED VIEW user_stats AS
SELECT 
    u.id,
    u.username,
    COUNT(DISTINCT ac.id) as conversation_count,
    COUNT(DISTINCT pt.id) as template_count,
    COUNT(DISTINCT rd.id) as requirement_count,
    SUM(ac.total_tokens) as total_tokens_used
FROM users u
LEFT JOIN ai_conversations ac ON u.id = ac.user_id AND ac.is_deleted = false
LEFT JOIN prompt_templates pt ON u.id = pt.user_id AND pt.is_deleted = false
LEFT JOIN requirement_documents rd ON u.id = rd.user_id AND rd.is_deleted = false
WHERE u.is_deleted = false
GROUP BY u.id, u.username;

-- åˆ›å»ºå”¯ä¸€ç´¢å¼•
CREATE UNIQUE INDEX idx_user_stats_id ON user_stats(id);

-- å®šæœŸåˆ·æ–°ç‰©åŒ–è§†å›¾
CREATE OR REPLACE FUNCTION refresh_user_stats()
RETURNS void AS $$
BEGIN
    REFRESH MATERIALIZED VIEW CONCURRENTLY user_stats;
END;
$$ LANGUAGE plpgsql;
```

## ðŸ”’ å®‰å…¨è®¾è®¡

### 1. æ•°æ®åŠ å¯†
```sql
-- å¯ç”¨è¡Œçº§å®‰å…¨
ALTER TABLE ai_model_configs ENABLE ROW LEVEL SECURITY;

-- åˆ›å»ºå®‰å…¨ç­–ç•¥
CREATE POLICY user_ai_models_policy ON ai_model_configs
FOR ALL TO authenticated_users
USING (user_id = current_setting('app.current_user_id')::uuid);

-- æ•æ„Ÿå­—æ®µåŠ å¯†å­˜å‚¨
-- api_key_encrypted å­—æ®µä½¿ç”¨åº”ç”¨å±‚åŠ å¯†
-- access_token_encrypted å­—æ®µä½¿ç”¨åº”ç”¨å±‚åŠ å¯†
```

### 2. å®¡è®¡æ—¥å¿—
```sql
-- åˆ›å»ºå®¡è®¡è§¦å‘å™¨
CREATE OR REPLACE FUNCTION audit_trigger_function()
RETURNS trigger AS $$
BEGIN
    IF TG_OP = 'INSERT' THEN
        INSERT INTO audit_logs (table_name, operation, new_data, user_id, created_at)
        VALUES (TG_TABLE_NAME, TG_OP, row_to_json(NEW), 
                current_setting('app.current_user_id', true)::uuid, 
                CURRENT_TIMESTAMP);
        RETURN NEW;
    ELSIF TG_OP = 'UPDATE' THEN
        INSERT INTO audit_logs (table_name, operation, old_data, new_data, user_id, created_at)
        VALUES (TG_TABLE_NAME, TG_OP, row_to_json(OLD), row_to_json(NEW),
                current_setting('app.current_user_id', true)::uuid,
                CURRENT_TIMESTAMP);
        RETURN NEW;
    ELSIF TG_OP = 'DELETE' THEN
        INSERT INTO audit_logs (table_name, operation, old_data, user_id, created_at)
        VALUES (TG_TABLE_NAME, TG_OP, row_to_json(OLD),
                current_setting('app.current_user_id', true)::uuid,
                CURRENT_TIMESTAMP);
        RETURN OLD;
    END IF;
    RETURN NULL;
END;
$$ LANGUAGE plpgsql;

-- ä¸ºé‡è¦è¡¨æ·»åŠ å®¡è®¡è§¦å‘å™¨
CREATE TRIGGER audit_users_trigger
AFTER INSERT OR UPDATE OR DELETE ON users
FOR EACH ROW EXECUTE FUNCTION audit_trigger_function();

CREATE TRIGGER audit_ai_model_configs_trigger
AFTER INSERT OR UPDATE OR DELETE ON ai_model_configs
FOR EACH ROW EXECUTE FUNCTION audit_trigger_function();
```

## ðŸ“Š ç›‘æŽ§å’Œç»´æŠ¤

### 1. æ€§èƒ½ç›‘æŽ§
```sql
-- æŸ¥è¯¢æ…¢æŸ¥è¯¢
SELECT query, mean_time, calls, total_time
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 10;

-- æŸ¥çœ‹è¡¨å¤§å°
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- æŸ¥çœ‹ç´¢å¼•ä½¿ç”¨æƒ…å†µ
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
ORDER BY idx_scan DESC;
```

### 2. æ•°æ®æ¸…ç†
```sql
-- å®šæœŸæ¸…ç†è½¯åˆ é™¤çš„æ•°æ®
CREATE OR REPLACE FUNCTION cleanup_soft_deleted_data()
RETURNS void AS $$
BEGIN
    -- æ¸…ç†30å¤©å‰è½¯åˆ é™¤çš„æ•°æ®
    DELETE FROM users WHERE is_deleted = true AND updated_at < NOW() - INTERVAL '30 days';
    DELETE FROM ai_model_configs WHERE is_deleted = true AND updated_at < NOW() - INTERVAL '30 days';
    DELETE FROM prompt_templates WHERE is_deleted = true AND updated_at < NOW() - INTERVAL '30 days';
    -- å…¶ä»–è¡¨...
END;
$$ LANGUAGE plpgsql;

-- å®šæœŸæ¸…ç†è¿‡æœŸçš„ä¼šè¯
CREATE OR REPLACE FUNCTION cleanup_expired_sessions()
RETURNS void AS $$
BEGIN
    DELETE FROM user_sessions WHERE expires_at < NOW();
END;
$$ LANGUAGE plpgsql;
```

---

